# Flow Based Generative Models with Virtual Bottleneck Compression

> Read the full report [here](https://github.com/elronbandel/flow-based-compression/blob/master/report.pdf)

Flow-Based models map complex spaces to latent distributions which are easy to sample from. Objects in the complex space can be generated by sampling from this latent distribution followed by a transformation using the inverse of the learned mapping. We propose a method to use such mappings for dimension reduction. We test this method on different data sets and several compression levels, achieving high log likelihood and clear generated images. We compare the results to the Variational Autoencoders (VAE) model, finding a similar digit outline quality. Hence, this method reduces dimension without harming the invertability and simplicity of the Flow-Based transformation by using a learn-able Virtual Bottleneck. By doing so, this method can preserve the desired invertability of Flow-Based models while simultaneously utilizing the advantages of a low-dimension latent representation. 

<p align="center">
  <img src="https://github.com/elronbandel/flow-based-compression/blob/c3567c73e63e2da7e4bd134d4d458c71453a20a0/plots/mnist_batch128_couplingadditive_mid2000_hidden10_compress8_.ptepoch75.png?raw=true" />
</p>

*Samples from compressed standard normal distribution latent space, transformed to 8 times larger MNIST images*

